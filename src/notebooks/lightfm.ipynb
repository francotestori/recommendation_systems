{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francotestori/dsuba/recommendation_systems/.venv/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from utils import ROOT_DIR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SEED = 671993\n",
    "\n",
    "SAMPLED_PLAYLISTS = 300000\n",
    "\n",
    "N_THREADS = 6\n",
    "N_EPOCHS = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.read_csv(f\"{ROOT_DIR}/data/mdp_playlists.csv\")\n",
    "interactions = pd.read_csv(f\"{ROOT_DIR}/data/mdp_interactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  5.,  11.,  15.,  18.,  22.,  26.,  30.,  34.,  39.,  44.,  49.,\n        55.,  62.,  70.,  80.,  92., 105., 123., 148., 184.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(\n",
    "    playlists.num_tracks,\n",
    "    np.arange(0,1,.05)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep a playlist subset\n",
    "filtered_playlists = playlists.query(\"num_tracks > 25\").sample(SAMPLED_PLAYLISTS, random_state=SEED)[[\"pid\"]]\n",
    "\n",
    "# With this filtered_playlist, we retrieve their interactions\n",
    "filtered_interactions = pd.merge(\n",
    "    interactions,\n",
    "    filtered_playlists,\n",
    "    on=\"pid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "24813480"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_interactions.track_uri.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge set\n",
    "challenge_set = pd.read_csv(f\"{ROOT_DIR}/data/mdp_challenge_set.csv\")[[\"pid\", \"track_uri\"]]\n",
    "\n",
    "# We generate interactions for lightFM\n",
    "interactions = pd.concat([filtered_interactions.drop(['pos'], axis = 1), challenge_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del playlists, filtered_playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset()\n",
    "data.fit(\n",
    "    interactions.pid.unique(),\n",
    "    interactions.track_uri.unique()\n",
    ")\n",
    "\n",
    "train, train_weights_matrix = data.build_interactions(\n",
    "    [tuple(i) for i in filtered_interactions.drop(['pos'], axis = 1).values]\n",
    ")\n",
    "test, test_weights_matrix = data.build_interactions(\n",
    "    [tuple(i) for i in challenge_set.values]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model.\n",
    "# Loss function can be either:\n",
    "# -BRP (Bayesian Personalised Ranking (optimise ROC/AUC)\n",
    "# -WARP (Weighted Approximate-RankPairwise (top of recommendation list optimization)\n",
    "# -K-WARP (warp-kos)\n",
    "model = LightFM(\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    max_sampled=20,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<lightfm.lightfm.LightFM at 0x7ff23b46a970>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "model.fit(\n",
    "    train,\n",
    "    epochs=N_EPOCHS,\n",
    "    num_threads=N_THREADS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<lightfm.lightfm.LightFM at 0x7ff23b46a970>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add test data\n",
    "model.fit_partial(\n",
    "    test,\n",
    "    num_threads=N_THREADS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 310000 - items: 1388000\n"
     ]
    }
   ],
   "source": [
    "# Number of Users (pid) & items (track_uri)\n",
    "n_users, n_items = train.shape\n",
    "print(f\"users: {n_users} - items: {n_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def batch_predict_recommended_tracks(\n",
    "        model: LightFM,\n",
    "        sampled_playlists: int,\n",
    "        tracks_array: List[str],\n",
    "        n_items: int,\n",
    "        n_users: int = 10000,\n",
    "        batch_size: int = 1000\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param sampled_playlists:\n",
    "    :param tracks_array:\n",
    "    :param n_items:\n",
    "    :param n_users:\n",
    "    :param batch_size: integer that has to be a denominator for 10k\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    start = sampled_playlists\n",
    "    iterations = int(n_users/batch_size)\n",
    "    recommendations = None\n",
    "\n",
    "    # TODO use tqdm\n",
    "    for i in tqdm(range(iterations), total=iterations):\n",
    "        # We create prediction arrays\n",
    "        users_id = np.repeat(\n",
    "            np.arange(start, start+batch_size),\n",
    "            n_items\n",
    "        )\n",
    "        items_id = np.tile(\n",
    "            np.arange(n_items),\n",
    "            batch_size\n",
    "        )\n",
    "\n",
    "        # We pararelize prediction\n",
    "        scores = model.predict(\n",
    "            users_id,\n",
    "            items_id,\n",
    "            num_threads=N_THREADS\n",
    "        )\n",
    "\n",
    "        # We create a prediction matrix\n",
    "        scores = np.reshape(\n",
    "            scores,\n",
    "            (batch_size, n_items)\n",
    "        )\n",
    "\n",
    "        # Ordenar por score predicho (obtengo los indices)\n",
    "        scores = np.argsort(-scores)\n",
    "\n",
    "        # Conservo el top 750. El challenge set tiene pids con a lo sumo 100 tracks\n",
    "        scores = scores[:, :750]\n",
    "\n",
    "        # Obtengo el track uri\n",
    "        recommended_tracks = tracks_array[scores]\n",
    "\n",
    "        if i == 0:\n",
    "            recommendations = recommended_tracks\n",
    "        elif i > 0:\n",
    "            recommendations = np.concatenate(\n",
    "                (recommendations, recommended_tracks)\n",
    "            )\n",
    "        print(\"Shape\", recommendations.shape)\n",
    "        start = start + batch_size\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_array = np.array(interactions.track_uri.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:36<49:32, 156.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [05:13<47:00, 156.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [07:33<42:16, 149.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [09:58<39:20, 147.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (2000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [12:34<37:36, 150.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (2500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [15:05<35:10, 150.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (3000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [17:17<31:20, 144.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (3500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [19:31<28:15, 141.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (4000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [21:47<25:36, 139.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (4500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [24:04<23:07, 138.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (5000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [26:16<20:29, 136.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (5500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [28:28<18:01, 135.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (6000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [30:54<16:10, 138.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (6500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [33:07<13:41, 136.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (7000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [35:21<11:20, 136.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (7500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [37:48<09:16, 139.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (8000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [40:28<07:16, 145.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (8500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [42:44<04:45, 142.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (9000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [45:25<02:28, 148.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (9500, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [47:53<00:00, 143.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (10000, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_recommended_tracks = batch_predict_recommended_tracks(\n",
    "    model=model,\n",
    "    sampled_playlists=SAMPLED_PLAYLISTS,\n",
    "    tracks_array=tracks_array,\n",
    "    n_items=n_items,\n",
    "    n_users=10000,\n",
    "    batch_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{ROOT_DIR}/results/challenge_set.pickle\", \"rb\") as f:\n",
    "    pid_track_uris = pickle.load(f)\n",
    "\n",
    "with open(f\"{ROOT_DIR}/results/tracks_interaction_count.pickle\", \"rb\") as f:\n",
    "    top_all = pickle.load(f)\n",
    "\n",
    "top_tracks = [pid for (_, pid) in sorted([(top_all[k],k) for k in top_all], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:15<00:00, 651.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "N_COLD_START = 5\n",
    "OS_PATH = f\"{ROOT_DIR}/results/lightfm.csv.gz\"\n",
    "\n",
    "with gzip.open(OS_PATH, 'wt') as submit_file:\n",
    "    _ = submit_file.write(\"team_info,francotestori,franco.testori@hotmail.com\\n\")\n",
    "\n",
    "    for i,pid in tqdm(enumerate(pid_track_uris), total=len(pid_track_uris)):\n",
    "        user_id = SAMPLED_PLAYLISTS + i\n",
    "\n",
    "        if len(pid_track_uris[pid]) > N_COLD_START:\n",
    "            top_recommendations = all_recommended_tracks[i]\n",
    "        else:\n",
    "            top_recommendations = top_tracks\n",
    "\n",
    "        tracks_recomendados = []\n",
    "        for tt in top_recommendations:\n",
    "            if tt in pid_track_uris[pid] or type(tt)==float:\n",
    "                continue\n",
    "            tracks_recomendados.append(\"spotify:track:\" + tt)\n",
    "            if len(tracks_recomendados) == 500:\n",
    "                break\n",
    "\n",
    "        _ = submit_file.write(f\"{pid},{','.join(tracks_recomendados)}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f354c6f4b71bc7f2b83bae277e5ae01a3b04e5fbd994a9538cd6e621402f0959"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('recsys': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}